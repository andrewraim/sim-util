---
title: "An Example Workflow Featuring a Regression Simulation"
author: Andrew Raim
output: 
  pdf_document:
    highlight: default
    number_sections: true
    toc: false
    extra_dependencies:
      common: null
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  prompt = TRUE,
  comment = ""
)
```

```{r setup, include = FALSE}
set.seed(1234)
```

# Introduction
\label{sec:intro}

This example illustrates a workflow for a simple simulation. Consider a linear regression model with
<!-- -->
\begin{align}
y_i = \vec{x}_i^\top \vec{\beta} + \epsilon_i, \quad
\epsilon_i \iid \text{N}(0, \sigma^2), \quad
i = 1, \ldots, n,
\label{eqn:reg-model}
\end{align}
<!-- -->
where $\vec{x}_i \in \mathbb{R}^d$ is a given covariate which is considered to be fixed. Let $\btheta = (\vec{\beta}, \sigma^2)$ represent the unknown parameters and let $\hat{\btheta} = (\hat{\vec{\beta}}, \hat{\sigma}^2)$ be the maximum likelihood estimator (MLE). Here the MLE has well-known closed form expressions
<!-- -->
\begin{align*}
\hat{\vec{\beta}} = (\vec{X}^\top \vec{X})^{-1} \vec{X}^\top \vec{y}, \quad
\hat{\sigma}^2 = \frac{1}{n} \vec{y}^\top (\vec{I} - \vec{H}) \vec{y},
\end{align*}
<!-- -->
where $\vec{X}$ is the $n \times d$ matrix with rows $\vec{x}_i^\top$ and $\vec{H} = \vec{X} (\vec{X}^\top \vec{X})^{-1} \vec{X}^\top$. A property of interest for the MLE is its mean-squared error
<!-- -->
\begin{align*}
\text{MSE}(\hat{\btheta}, \btheta) = \E\left[ \lVert \hat{\btheta} - \btheta \rVert^2 \right]
\end{align*}
<!-- -->
with respect to the true data generating parameter $\btheta$. We will prepare a small simulation to evaluate the MSE for $\beta = (-1, 1)$, $\sigma \in \{1, 2, 3\}$, and $n \in \{ 50, 100, 200 \}$. For each combination of $(\sigma, n)$ ("level" of the simulation), we will repeat the following for $r = 1, \ldots, R = 200$: first generate observations $\vec{y}^{(r)} = (y_1^{(r)}, \ldots, y_n^{(r)})$ from model \eqref{eqn:reg-model} using the current level of $\btheta$ and $n$, then obtain the MLE $\hat{\btheta}^{(r)}$. Using the empirical sampling distribution of $\hat{\btheta}^{(1)}, \ldots, \hat{\btheta}^{(R)}$, we may then approximate
<!-- -->
\begin{align*}
\text{MSE}(\hat{\btheta}, \btheta) \approx \frac{1}{R} \sum_{r=1}^R \lVert \hat{\btheta}^{(r)} - \btheta \rVert^2
\end{align*}
<!-- -->
This simple simulation can be run within an R script in a matter of seconds or minutes. We can create nested loops to iterate through the crossed levels of $\sigma$ and $n$, and then the $R$ repetitions. Now imagine a more involved study where computing each estimate takes a matter of minutes or hours. Also, instead of having only 9 levels of the simulation, perhaps we have hundreds. Rather than saving just the MLE repetitions, we may also want to save the generated data $\vec{y}^{(r)}$, and diagnostics from each fit. This motivates the following workflow:
<!-- -->
\begin{itemize}
\item Each level of the simulation will be placed into its own dedicated folder with a launcher script. Any log files and output from the level will be saved here as well.
\item The folders and launcher scripts will be generated by a script that we write.
\item We will utilize one or more "workers", whose job is to search the folders for available work. A folder is reserved and has its launcher executed by at most one worker.
\item If a level fails, or if we wish to investigate its result, we can manually enter the folder and run the launcher or load the results.
\item We will write a script to extract results from the folders and produce the desired results.
\end{itemize}
<!-- -->

This kind of "embarrassingly parallel" computing is typical in many statistical projects: no communication is needed across levels during the simulation. Coordination is only needed to initially generated the workload and in post-processing. We may therefore wish to take advantage of multiple CPUs to process our workload faster, without the extra sophistication of frameworks such as MPI or the `parallel` package.

# Workflow Implementation
\label{sec:workflow}

The following scripts are used to implement our workflow for the regression simulation:
<!-- -->
\begin{itemize}
\item `gen.R` generates the folder structure and creates a `launch.R` script in  each folder.
\item `util.R` contains several utility functions used by other scripts.
\item `sim.R` contains the main logic to run each level of the simulation. The program sleeps for a few moments after each repetition to give the feeling of a more computationally demanding simulation.
\item `launch.R` is responsible for setting variables specific to the simulation level and running `sim.R`.
\item `worker.py` is a Python script that seeks simulation levels which have yet been run and attempts to run them.
\item `analyze.R` handles post-processing after the simulation is completed. A table of MSEs is presented as the final result.
\end{itemize}
<!-- -->

All scripts mentioned above, except for `worker.py`, are specific to this simulation and must be rewritten or customized for other applications.

Let us run `gen.R` on the command line. The following displays will shown as a Linux prompt, but other environments should work similarly.

```bash
$ R CMD BATCH gen.R
```

The following folders and directories are produced.

```
sigma1_n1  sigma1_n3  sigma2_n2  sigma3_n1  sigma3_n3    xmat-n2.rds
sigma1_n2  sigma2_n1  sigma2_n3  sigma3_n2  xmat-n1.rds  xmat-n3.rds
```

Folders of the form `sigmaA_nB` correspond to the simulation level for the $A$th value of $\sigma$ and the $B$th value of $n$, for $A,B \in \{ 1, 2, 3 \}$. Files of the form `xmat-nB.rds` represent the design matrix $\vec{X}$ to be used when $n$ is taken to be the $B$th level.

Let's inspect `launch.R` in the folder `sigma1_n1`.

```r
set.seed(1234)

beta_true = c(-1,1)
sigma_true = 2.000000
xmat_file = "../xmat-n1.rds"
N_sim = 200

source("../sim.R")
save.image("results.Rdata")
```

We could run this manually to verify that our code generation script is correct and that all resources are in the appropriate place. Note that it assumes the `sigma1_n1` folder is our current working directory. Furthermore, `sim.R` and `xmat-n1.rds` should be in the parent directory.

Once we are certain the code and folders are laid out correctly, we will want to use a worker(s) instead of running the study manually. Suppose
<!-- -->
\begin{itemize}
\item The script `worker.py` is located at `/path/to/worker.py`.
\item The path to our generated simulation folders is located at `/path/to/study`.
\end{itemize}
<!-- -->
The following command invokes one worker.

```bash
python3 /path/to/worker.py -b /path/to/study -p "sigma(.*)_n(.*)" -c 'R CMD BATCH launch.R'
```

Note that `-b` is used to specify one or more paths which contain work folders, `-p` is used to specify one or more patterns used to identify work folders (as opposed to other folders which we should ignore), and `-c` specifies a command to run if we find a work folder whose job has not yet been attempted. Use the `-h` flag to display a help message, including the command line format, for `worker.py`.

A worker logs its activity to stdout. This can be redirected to a file if desired.

```bash
2021-06-09 18:16:05 - Worker ID: 75e1421210cc92d62e5403313cab33f0
2021-06-09 18:16:05 - Working directory: /sim-util/examples/regression-sim
2021-06-09 18:16:05 - Searching 1 basepaths for available work
2021-06-09 18:16:05 - Basepath[0]: /sim-util/examples/regression-sim  
                      Pattern: sigma(.*)_n(.*)
2021-06-09 18:16:05 - Lockfile in sigma2_n2 exists, skipping
2021-06-09 18:16:05 - Lockfile in sigma1_n2 exists, skipping
2021-06-09 18:16:05 - Lockfile in sigma1_n3 exists, skipping
2021-06-09 18:16:05 - Lockfile in sigma2_n1 acquired
2021-06-09 18:19:25 - Processed 1 jobs and worked for 0.055721 total hours so far
2021-06-09 18:19:25 - Lockfile in sigma3_n1 acquired
```

Let us look in `sigma2_n1`, which was completed by the worker above.

```bash
$ ls sigma2_n1
launch.R  launch.Rout  results.Rdata  worker.err  worker.lock  worker.out
```

The files `worker.out` and `worker.err` capture any output from stdout and stderr while running the job. The file `worker.lock` is placed as a marker to indicate that a job has been reserved by a worker; only one worker may create this file, and it can run the job only upon successful creation of the file. If a job fails and you would like a worker to consider it again, delete the corresponding `worker.lock`.

The file `worker.lock` contains the ID of the worker that reserved it. This can be linked back to the `Worker ID` reported in the log output, which may help if it is necessary to determine which worker ran a job.

```bash
$ cat sigma2_n1/worker.lock
Reserved by worker: 75e1421210cc92d62e5403313cab33f0
```

When working on a remote server, it may not be possible to keep a persistent session open for long periods that may be needed for a simulation study. In a setting where a scheduler such as [PBS](https://www.openpbs.org) or [Slurm](https://slurm.schedmd.com) is used to allocate jobs to compute nodes, each worker may be submitted as a job to the scheduler. In an environment without a scheduler, running workers via a terminal multiplexer such as [tmux](https://tmux.github.io) or [GNU screen](https://www.gnu.org/software/screen) allows terminal sessions to detach and reattach as needed to provide some persistence.

After the simulation is complete, we may run `analyze.R` to extract the estimates from each folder and build a table of MSEs.

```r
R> source("analyze.R")
               n1         n2         n3
sigma1 0.07391762 0.03495352 0.01905428
sigma2 0.71125615 0.30743114 0.18523518
sigma3 3.15877261 1.32028399 0.82559688
```

As we may expect, the MSE increases as $\sigma$ increases with $n$ fixed, but decreases when $n$ is increased and $\sigma$ is fixed.
